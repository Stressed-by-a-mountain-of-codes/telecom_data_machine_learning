{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d94975-202c-421d-a472-23864afe70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a930e159-7285-4546-9b93-3c56ef3052e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load the dataset from the data folder\n",
    "df = pd.read_csv('../data/Telco_Customer_Churn_Dataset.csv')\n",
    "\n",
    "# Show the first 5 rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70a38bd-7236-49f0-8003-5389814cf6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (7043, 21)\n",
      "\n",
      "Column data types and non-null counts:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Basic dataset info\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nColumn data types and non-null counts:\\n\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea106ee8-b32c-4dd5-b832-ee402558baeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'TotalCharges': 11\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Convert 'TotalCharges' to numeric, force errors to NaN\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Check how many missing values were created\n",
    "print(\"Missing values in 'TotalCharges':\", df['TotalCharges'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14411cc-0393-4286-874d-ebbe9b80e87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after dropping: 0\n",
      "New dataset shape: (7032, 21)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Drop rows with missing 'TotalCharges'\n",
    "df = df.dropna(subset=['TotalCharges'])\n",
    "\n",
    "# Confirm they're gone\n",
    "print(\"Missing values after dropping:\", df['TotalCharges'].isna().sum())\n",
    "print(\"New dataset shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2025f856-0c82-4c83-a7ed-121a4d2cd1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns:\n",
      " ['customerID', 'gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'Churn']\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Check categorical columns\n",
    "cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "print(\"Categorical Columns:\\n\", cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28b5f35d-8962-4127-93ec-0aa4f84d0978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding done for binary columns.\n",
      "One-Hot Encoding done for nominal columns.\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Encode Categorical Variables\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# List of binary categorical columns for Label Encoding\n",
    "label_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'PaperlessBilling', 'Churn']\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to binary categorical columns\n",
    "for col in label_cols:\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "print(\"Label Encoding done for binary columns.\")\n",
    "\n",
    "# One-hot encode nominal categorical columns\n",
    "df = pd.get_dummies(df, columns=['InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                                  'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', \n",
    "                                  'PaymentMethod'], drop_first=True)\n",
    "\n",
    "print(\"One-Hot Encoding done for nominal columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f804e00-b9e2-4769-8f6a-66181ca29cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split done.\n",
      "Training data shape: (5625, 30)\n",
      "Test data shape: (1407, 30)\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Train-Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop('Churn', axis=1)  # All columns except 'Churn'\n",
    "y = df['Churn']  # Target variable\n",
    "\n",
    "# Split data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train-Test Split done.\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a2d87dc-b320-4227-ae12-633ea588d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after encoding:\n",
      " ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'PaperlessBilling', 'MonthlyCharges', 'TotalCharges', 'InternetService_Fiber optic', 'InternetService_No', 'OnlineSecurity_No internet service', 'OnlineSecurity_Yes', 'OnlineBackup_No internet service', 'OnlineBackup_Yes', 'DeviceProtection_No internet service', 'DeviceProtection_Yes', 'TechSupport_No internet service', 'TechSupport_Yes', 'StreamingTV_No internet service', 'StreamingTV_Yes', 'StreamingMovies_No internet service', 'StreamingMovies_Yes', 'Contract_One year', 'Contract_Two year', 'PaymentMethod_Credit card (automatic)', 'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check']\n"
     ]
    }
   ],
   "source": [
    "# Step: Check column names after encoding\n",
    "print(\"Columns after encoding:\\n\", X_train.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "284c9c32-e09c-4d35-abb0-2ad83f319117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection done.\n",
      "Training data shape after feature selection: (5625, 6)\n",
      "Test data shape after feature selection: (1407, 6)\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Feature Selection\n",
    "\n",
    "# Choose key features manually (with updated column names)\n",
    "selected_features = ['tenure', 'MonthlyCharges', 'Contract_One year', 'Contract_Two year', \n",
    "                     'InternetService_Fiber optic', 'PaymentMethod_Electronic check']\n",
    "\n",
    "# Update X_train and X_test to include only the selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "print(\"Feature Selection done.\")\n",
    "print(f\"Training data shape after feature selection: {X_train_selected.shape}\")\n",
    "print(f\"Test data shape after feature selection: {X_test_selected.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1b29367-d999-4d47-9f89-c7186e38b933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "Accuracy: 0.7861\n",
      "Precision: 0.6281\n",
      "Recall: 0.4786\n",
      "F1-Score: 0.5432\n",
      "ROC-AUC: 0.6880\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Model Selection\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model on the selected training data\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f2452fa-3db7-47e6-8c53-2a7fc6aeeb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "\n",
    "# Plot confusion matrix and save it\n",
    "cm_display.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.savefig('C:/Users/heave/OneDrive/Desktop/customer-churn-prediction/outputs/graphs/logistic_regression_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Generate ROC curve and save it\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - Logistic Regression')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('C:/Users/heave/OneDrive/Desktop/customer-churn-prediction/outputs/graphs/logistic_regression_roc_curve.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34f61e57-7431-43fd-90e5-92bc70860bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model saved at: C:/Users/heave/OneDrive/Desktop/customer-churn-prediction/models/logistic_regression_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Define the path where you want to save the logistic regression model\n",
    "logreg_model_path = 'C:/Users/heave/OneDrive/Desktop/customer-churn-prediction/models/logistic_regression_model.pkl'\n",
    "\n",
    "# Save the logistic regression model\n",
    "joblib.dump(model, logreg_model_path)\n",
    "\n",
    "print(f\"Logistic Regression Model saved at: {logreg_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90dc2806-9d58-4f91-aa77-efe91297a175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Evaluation Metrics:\n",
      "Accuracy: 0.7342\n",
      "Precision: 0.5000\n",
      "Recall: 0.5187\n",
      "F1-Score: 0.5092\n",
      "ROC-AUC: 0.6655\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Model Selection - Decision Tree Classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the Decision Tree model\n",
    "dt_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_dt = dt_model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "roc_auc_dt = roc_auc_score(y_test, y_pred_dt)\n",
    "\n",
    "# Print the evaluation metrics for the Decision Tree model\n",
    "print(\"Decision Tree Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_dt:.4f}\")\n",
    "print(f\"Precision: {precision_dt:.4f}\")\n",
    "print(f\"Recall: {recall_dt:.4f}\")\n",
    "print(f\"F1-Score: {f1_dt:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_dt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cfbfc34-34a5-4392-b1cb-4b38a865625f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model saved at: C:\\Users\\heave\\OneDrive\\Desktop\\customer-churn-prediction\\models\\decision_tree_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# Define the target directory\n",
    "model_dir = r'C:\\Users\\heave\\OneDrive\\Desktop\\customer-churn-prediction\\models'\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Save the trained Decision Tree model to a file\n",
    "dt_model_path = os.path.join(model_dir, 'decision_tree_model.pkl')\n",
    "joblib.dump(dt_model, dt_model_path)\n",
    "print(f\"Decision Tree Model saved at: {dt_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b4ce0e1-336f-4734-885f-f32526aec67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Evaluation Metrics:\n",
      "Accuracy: 0.7562\n",
      "Precision: 0.5492\n",
      "Recall: 0.4626\n",
      "F1-Score: 0.5022\n",
      "ROC-AUC: 0.6626\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Model Selection - Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_rf = rf_model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "# Print the evaluation metrics for the Random Forest model\n",
    "print(\"Random Forest Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"Precision: {precision_rf:.4f}\")\n",
    "print(f\"Recall: {recall_rf:.4f}\")\n",
    "print(f\"F1-Score: {f1_rf:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e1119bd-d397-4a21-8467-ec4d5cf92ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "\n",
    "# Generate confusion matrix for Random Forest model\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "cm_display_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=rf_model.classes_)\n",
    "\n",
    "# Plot confusion matrix and save it\n",
    "cm_display_rf.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - Random Forest\")\n",
    "plt.savefig('C:/Users/heave/OneDrive/Desktop/customer-churn-prediction/outputs/graphs/random_forest_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Generate ROC curve for Random Forest model and save it\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_pred_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_rf)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - Random Forest')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('C:/Users/heave/OneDrive/Desktop/customer-churn-prediction/outputs/graphs/random_forest_roc_curve.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d01da0bf-efd4-4ce3-a532-9bf80577041b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: ../models/random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained RandomForest model\n",
    "model_path = '../models/random_forest_model.pkl'  # going one level up from notebooks/\n",
    "joblib.dump(rf_model, model_path)\n",
    "\n",
    "print(f\"Model saved at: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f1aac81-8283-4726-ba75-a99637b98ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 1, 'max_iter': 500, 'solver': 'newton-cg'}\n",
      "Logistic Regression Model Evaluation Metrics:\n",
      "Accuracy: 0.7861\n",
      "Precision: 0.6281\n",
      "Recall: 0.4786\n",
      "F1-Score: 0.5432\n",
      "ROC-AUC: 0.6880\n"
     ]
    }
   ],
   "source": [
    "# Step 13: Hyperparameter Tuning - Logistic Regression\n",
    "\n",
    "# Importing required libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Step 13.1: Scale the data\n",
    "# Scaling features to ensure better performance of Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# Step 13.2: Define the hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'solver': ['lbfgs', 'newton-cg', 'saga'],  # Different solvers for better convergence\n",
    "    'max_iter': [500, 1000],  # Increase the number of iterations for convergence\n",
    "    'C': [0.1, 1, 10]  # Regularization strength\n",
    "}\n",
    "\n",
    "# Step 13.3: Initialize Logistic Regression model\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Step 13.4: Perform Grid Search with Cross Validation\n",
    "grid_search_lr = GridSearchCV(estimator=lr_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 13.5: Display the best parameters from Grid Search\n",
    "print(\"Best Parameters: \", grid_search_lr.best_params_)\n",
    "\n",
    "# Step 13.6: Evaluate the model on Test Data\n",
    "y_pred_lr = grid_search_lr.predict(X_test_scaled)\n",
    "\n",
    "# Step 13.7: Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "precision = precision_score(y_test, y_pred_lr)\n",
    "recall = recall_score(y_test, y_pred_lr)\n",
    "f1 = f1_score(y_test, y_pred_lr)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_lr)\n",
    "\n",
    "# Step 13.8: Print the evaluation metrics for the Logistic Regression model\n",
    "print(f\"Logistic Regression Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b443b3f9-5eb0-4c82-958e-94ff9c75e17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best Parameters: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "\n",
      "Random Forest Model Evaluation Metrics:\n",
      "Accuracy: 0.7811\n",
      "Precision: 0.6086\n",
      "Recall: 0.4947\n",
      "F1-Score: 0.5457\n",
      "ROC-AUC: 0.6897\n"
     ]
    }
   ],
   "source": [
    "# Step 14: Hyperparameter Tuning - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params_rf = grid_search.best_params_\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best Parameters:\", best_params_rf)\n",
    "\n",
    "# Evaluate the tuned Random Forest model\n",
    "y_pred_rf = best_rf_model.predict(X_test_selected)\n",
    "\n",
    "# Metrics for evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"Precision: {precision_rf:.4f}\")\n",
    "print(f\"Recall: {recall_rf:.4f}\")\n",
    "print(f\"F1-Score: {f1_rf:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e819f-1326-480e-97c0-d4e569d7c4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
